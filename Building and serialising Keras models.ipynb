{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "!pip install --upgrade keras-applications keras-preprocessing setuptools tensorflow==1.14.0 keras==2.2.5", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "import tensorflow\nif not tensorflow.__version__ == '1.14.0':\n    print(tensorflow.__version__)\n    raise ValueError('please upgrade to TensorFlow 1.14.0, or restart your Kernel (Kernel->Restart & Clear Output)')\n\nimport keras\nif not keras.__version__ == '2.2.5':\n    print(keras.__version__)\n    raise ValueError('please upgrade to Keras 2.2.5, or restart your Kernel (Kernel->Restart & Clear Output)')", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\nseed = 1337\nnp.random.seed(seed)\nfrom keras.datasets import reuters\n\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=seed)\nnum_classes = np.max(y_train) + 1  # 46 topics", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191011133059-0001\nKERNEL_ID = e1dd024b-8314-45af-8b0c-0cbfc7a96471\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/spark/shared/user-libs/python3.6/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/spark/shared/user-libs/python3.6/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n2113536/2110848 [==============================] - 1s 0us/step\n"
                }
            ], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# 1. Exercise part: label encoding", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "y_train = to_categorical(y_train, num_classes)###_YOUR_CODE_GOES_HERE_###\ny_test = to_categorical(y_test, num_classes)###_YOUR_CODE_GOES_HERE_###", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# 2. Exercise part: model definition", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model = Sequential()###_YOUR_CODE_GOES_HERE_###  # Instantiate sequential model\nmodel.add(Dense(512, activation= 'relu', input_shape= (max_words,)))###_YOUR_CODE_GOES_HERE_###) # Add first layer. Make sure to specify input shape\nmodel.add(Dropout(0.5))###_YOUR_CODE_GOES_HERE_###) # Add second layer\nmodel.add(Dense(num_classes, activation= 'softmax'))###_YOUR_CODE_GOES_HERE_###) # Add third layer", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# 3. Exercise part: model compilation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])###_YOUR_CODE_GOES_HERE_###)", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# 4. Exercise part: model training and evaluation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "batch_size = 32###_YOUR_CODE_GOES_HERE_###\nmodel.fit(x_train, y_train, batch_size= batch_size, epochs= 5, validation_data= (x_test, y_test))###_YOUR_CODE_GOES_HERE_###)\nscore = model.evaluate(x_test, y_test)###_YOUR_CODE_GOES_HERE_###)", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /home/spark/shared/user-libs/python3.6/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 8982 samples, validate on 2246 samples\nEpoch 1/5\n8982/8982 [==============================] - 3s 320us/step - loss: 1.3847 - acc: 0.6916 - val_loss: 0.9597 - val_acc: 0.7823\nEpoch 2/5\n8982/8982 [==============================] - 2s 253us/step - loss: 0.7702 - acc: 0.8205 - val_loss: 0.8426 - val_acc: 0.8023\nEpoch 3/5\n8982/8982 [==============================] - 2s 255us/step - loss: 0.5449 - acc: 0.8675 - val_loss: 0.8131 - val_acc: 0.8037\nEpoch 4/5\n8982/8982 [==============================] - 2s 257us/step - loss: 0.4170 - acc: 0.8966 - val_loss: 0.8178 - val_acc: 0.8059\nEpoch 5/5\n8982/8982 [==============================] - 2s 256us/step - loss: 0.3511 - acc: 0.9087 - val_loss: 0.8603 - val_acc: 0.7979\n2246/2246 [==============================] - 0s 36us/step\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "score[1]", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.7978628673196795"
                    }, 
                    "execution_count": 9
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# 5. Exercise part: model serialisation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model.save(\"model.h5\")  # upload this file to the grader in the next code block", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "!base64 model.h5 > model.h5.base64", 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py", 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-10-11 14:19:14--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.60.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.60.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2289 (2.2K) [text/plain]\nSaving to: 'rklib.py'\n\n100%[======================================>] 2,289       --.-K/s   in 0s      \n\n2019-10-11 14:19:14 (25.3 MB/s) - 'rklib.py' saved [2289/2289]\n\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "from rklib import submit\nkey = \"XbAMqtjdEeepUgo7OOVwng\"\npart = \"HCvcp\"\nemail = \"sbisenbaeva@edu.hse.ru\"\nsecret = \"Vxs4EoXj3ZLLPsQn\"\n\nwith open('model.h5.base64', 'r') as myfile:\n    data=myfile.read()\nsubmit(email, secret, key, part, [part], data)", 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Something went wrong, please have a look at the reponse of the grader\n-------------------------\n{\"errorCode\":\"7den6cb0d\"}\n-------------------------\n"
                }
            ], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}